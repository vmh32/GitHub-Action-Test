name: 'NuGet Package Build and Release'
description: 'Build and release NuGet packages with dependency management'

inputs:
  projects:
    description: 'Project configurations in JSON format'
    required: true
  dotnet_version:
    description: '.NET version to use'
    required: false
    default: '8.0.x'
  configuration:
    description: 'Build configuration'
    required: false
    default: 'Release'
  github_token:
    description: 'GitHub token for package publishing'
    required: true
  git_user_email:
    description: 'Git user email for commits'
    required: false
    default: 'action@github.com'
  git_user_name:
    description: 'Git user name for commits'
    required: false
    default: 'GitHub Action'

outputs:
  changed_projects:
    description: 'List of projects that were changed'
    value: ${{ steps.order.outputs.modified_packages }}
  version_changes:
    description: 'Summary of version changes made'
    value: ${{ steps.versions.outputs.version_changes }}
  created_tags:
    description: 'List of Git tags created'
    value: ${{ steps.tags.outputs.tags }}

runs:
  using: "composite"
  steps:
    - name: Setup Environment
      shell: bash
      run: |
        echo "DOTNET_VERSION=${{ inputs.dotnet_version }}" >> $GITHUB_ENV
        echo "GITHUB_PACKAGES_URL=https://nuget.pkg.github.com/${{ github.repository_owner }}/index.json" >> $GITHUB_ENV
        echo "NUGET_AUTH_TOKEN=${{ inputs.github_token }}" >> $GITHUB_ENV
        echo "CONFIGURATION=${{ inputs.configuration }}" >> $GITHUB_ENV
        echo "PR_BRANCH=${{ github.head_ref }}" >> $GITHUB_ENV
        echo "GIT_USER_EMAIL=${{ inputs.git_user_email }}" >> $GITHUB_ENV
        echo "GIT_USER_NAME=${{ inputs.git_user_name }}" >> $GITHUB_ENV
        echo "OUTPUT_DIR=./nupkg" >> $GITHUB_ENV

    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Generate Configuration
      id: config
      shell: python
      run: |
        import json
        import os
        import sys
        from pathlib import Path

        def process_projects(projects_json):
            projects = json.loads(projects_json)
            
            # Create package mapping
            package_map = {}
            filters = {}
            
            for idx, (project_id, config) in enumerate(projects.items(), 1):
                key = f"X{idx}"
                path = config['path']
                patterns = config.get('patterns', [f"{project_id}/**"])
                deps = config.get('dependencies', [])
                
                # Create package map entry
                package_map[key] = f"{project_id}:{path}:{'+'.join(deps)}"
                
                # Create filter entry
                filters[key] = patterns
            
            return package_map, filters

        def main():
            # Get input
            projects_json = os.environ['INPUT_PROJECTS']
            
            # Process projects
            package_map, filters = process_projects(projects_json)
            
            # Ensure scripts directory exists
            Path('scripts').mkdir(exist_ok=True)
            
            # Write package map
            with open('scripts/package_map.json', 'w') as f:
                json.dump(package_map, f, indent=2)
            
            # Generate filters YAML
            filters_yaml = "filters: |\n"
            for key, patterns in filters.items():
                filters_yaml += f"  {key}:\n"
                for pattern in patterns:
                    filters_yaml += f"    - '{pattern}'\n"
            
            # Write to GITHUB_OUTPUT
            with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                f.write(filters_yaml)

        if __name__ == '__main__':
            main()

    - name: Detect Changed Packages
      id: filter
      uses: dorny/paths-filter@v3
      with: ${{ fromJSON(steps.config.outputs.filters) }}

    - name: Order Dependencies
      id: order
      shell: bash
      run: |
        python3 - << 'EOF'
        import json
        import sys
        import os
        from collections import defaultdict

        def load_package_map():
            with open('scripts/package_map.json', 'r') as f:
                return json.load(f)

        def create_graph(items, package_map):
            graph = defaultdict(list)
            nodes = set()
            
            # Create reverse mapping from library id to key
            lib_to_key = {}
            for key, value in package_map.items():
                lib_id = value.split(':')[0]
                lib_to_key[lib_id] = key
            
            # Parse the items and build the graph
            for item in items:
                key = item.strip('"')
                if key in package_map:
                    parts = package_map[key].split(':')
                    deps = parts[2].split('+') if parts[2] else []
                    nodes.add(key)
                    for dep in deps:
                        if dep and dep in lib_to_key:
                            dep_key = lib_to_key[dep]
                            if dep_key in package_map:
                                graph[key].append(dep_key)
                                nodes.add(dep_key)
            return graph, nodes

        def topological_sort(graph, nodes):
            visited = set()
            temp = set()
            order = []
            
            def visit(node):
                if node in temp:
                    sys.exit(f"Error: Circular dependency detected involving {node}")
                if node not in visited:
                    temp.add(node)
                    for dep in graph[node]:
                        visit(dep)
                    temp.remove(node)
                    visited.add(node)
                    order.append(node)
            
            for node in nodes:
                if node not in visited:
                    visit(node)
            
            return order

        # Load package mapping
        package_map = load_package_map()

        # Get the changes from GitHub Actions environment
        changes = '${{ steps.filter.outputs.changes }}'
        if changes == '[]':
            with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                f.write('ordered_changes=[]\n')
                f.write('modified_packages=[]\n')
                f.write('has_nuspec=false\n')
            sys.exit(0)

        # Remove brackets and split into items
        modified_packages = [item.strip().strip('"') for item in changes.strip('[]').split(',')]
        
        # Create dependency graph
        graph, nodes = create_graph(modified_packages, package_map)
        
        # Get topological order
        ordered_keys = topological_sort(graph, nodes)
        
        # Check if any of the MODIFIED packages contain .nuspec
        has_nuspec = any('.nuspec' in package_map[key] for key in modified_packages if key in package_map)
        
        # Output the results
        with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
            f.write(f'ordered_changes=[{",".join(ordered_keys)}]\n')
            f.write(f'modified_packages=[{",".join(modified_packages)}]\n')
            f.write(f'has_nuspec={str(has_nuspec).lower()}\n')
        EOF

    # Rest of the existing steps from build.yml...
    # (Version updates, commit changes, setup .NET, etc.) 

    - name: Get PR Comments
      id: pr_comment
      uses: actions/github-script@v7
      with:
        script: |
          const { data: comments } = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number
          });
          const prBody = context.payload.pull_request.body || '';
          const allText = [prBody, ...comments.map(c => c.body)].join('\n');
          return allText;
        result-encoding: string

    - name: Update Versions
      shell: bash
      id: versions
      run: |
        python3 - << 'EOF'
        import xml.etree.ElementTree as ET
        import re
        import sys
        import os
        import glob
        import json

        def debug_log(message, data=None):
            print(f"\n=== DEBUG: {message} ===")
            if data is not None:
                print(f"Data: {repr(data)}")
            print("=" * (len(message) + 16))

        def load_package_map():
            with open('scripts/package_map.json', 'r') as f:
                return json.load(f)

        # Register the namespace to avoid ns0 prefix
        ET.register_namespace('', 'http://schemas.microsoft.com/packaging/2010/07/nuspec.xsd')

        def parse_version(version_str):
            debug_log("Parsing version string", version_str)
            match = re.match(r'(\d+)\.(\d+)\.(\d+)', version_str)
            if not match:
                debug_log("Failed to parse version", version_str)
                return (0, 0, 0)
            return tuple(map(int, match.groups()))

        def get_version_from_file(file_path):
            debug_log("Reading version from file", file_path)
            try:
                if file_path.endswith('.csproj'):
                    tree = ET.parse(file_path)
                    version_elem = tree.find(".//Version")
                    version = version_elem.text if version_elem is not None else "1.0.0"
                    debug_log("Found version in csproj", version)
                    return version
                elif file_path.endswith('.nuspec'):
                    tree = ET.parse(file_path)
                    ns = {'ns': 'http://schemas.microsoft.com/packaging/2010/07/nuspec.xsd'}
                    version_elem = tree.find(".//ns:version", ns)
                    version = version_elem.text if version_elem is not None else "1.0.0"
                    debug_log("Found version in nuspec", version)
                    return version
            except Exception as e:
                debug_log(f"Error reading version from {file_path}", str(e))
                raise
            return "1.0.0"

        def update_version_in_file(file_path, new_version):
            debug_log(f"Updating version in {file_path} to {new_version}")
            try:
                if file_path.endswith('.csproj'):
                    tree = ET.parse(file_path)
                    version_elem = tree.find(".//Version")
                    if version_elem is not None:
                        version_elem.text = new_version
                    tree.write(file_path, encoding='utf-8', xml_declaration=True)
                elif file_path.endswith('.nuspec'):
                    tree = ET.parse(file_path)
                    ns = {'ns': 'http://schemas.microsoft.com/packaging/2010/07/nuspec.xsd'}
                    version_elem = tree.find(".//ns:version", ns)
                    if version_elem is not None:
                        version_elem.text = new_version
                    tree.write(file_path, encoding='utf-8', xml_declaration=True)
            except Exception as e:
                debug_log(f"Error updating version in {file_path}", str(e))
                raise

        def update_dependency_version(file_path, dep_key, new_version):
            debug_log(f"Updating dependency {dep_key} to version {new_version} in {file_path}")
            updated = False
            try:
                if file_path.endswith('.csproj'):
                    tree = ET.parse(file_path)
                    for pkg_ref in tree.findall(".//PackageReference[@Include='Library{}']".format(dep_key)):
                        old_version = pkg_ref.get('Version')
                        pkg_ref.set('Version', new_version)
                        updated = True
                        debug_log(f"Updated PackageReference version", f"from {old_version} to {new_version}")
                    if updated:
                        tree.write(file_path, encoding='utf-8', xml_declaration=True)
                elif file_path.endswith('.nuspec'):
                    tree = ET.parse(file_path)
                    ns = {'ns': 'http://schemas.microsoft.com/packaging/2010/07/nuspec.xsd'}
                    for dep in tree.findall(".//ns:dependency[@id='Library{}']".format(dep_key), ns):
                        old_version = dep.get('version')
                        dep.set('version', new_version)
                        updated = True
                        debug_log(f"Updated dependency version", f"from {old_version} to {new_version}")
                    if updated:
                        tree.write(file_path, encoding='utf-8', xml_declaration=True)
            except Exception as e:
                debug_log(f"Error updating dependency in {file_path}", str(e))
                raise
            return updated

        def get_library_info(file_path):
            """Extract library name and its dependencies from a file."""
            deps = []
            if file_path.endswith('.csproj'):
                tree = ET.parse(file_path)
                # Get package references
                for ref in tree.findall(".//PackageReference"):
                    pkg_name = ref.get('Include', '')
                    if pkg_name.startswith('Library'):
                        deps.append(pkg_name.replace('Library', ''))
            elif file_path.endswith('.nuspec'):
                tree = ET.parse(file_path)
                ns = {'ns': 'http://schemas.microsoft.com/packaging/2010/07/nuspec.xsd'}
                # Get dependencies
                for dep in tree.findall(".//ns:dependency", ns):
                    dep_id = dep.get('id', '')
                    if dep_id.startswith('Library'):
                        deps.append(dep_id.replace('Library', ''))
            
            # Extract library name from path
            lib_name = os.path.basename(os.path.dirname(file_path)).replace('Library', '')
            return lib_name, deps

        def scan_all_libraries():
            """Scan workspace for all libraries and their dependencies."""
            library_info = {}
            
            # Find all .csproj and .nuspec files
            for pattern in ['*/*.csproj', '*/*.nuspec']:
                for file_path in glob.glob(pattern):
                    lib_name, deps = get_library_info(file_path)
                    if lib_name:
                        if lib_name not in library_info:
                            library_info[lib_name] = {'file_path': file_path, 'dependencies': set()}
                        library_info[lib_name]['dependencies'].update(deps)
            
            return library_info

        def calculate_new_version(current_version, key, pr_comments):
            major, minor, patch = parse_version(current_version)
            
            # Check for version change indicators in PR comments
            if f'[BREAKING_CHANGE:{key}]' in pr_comments:
                return f"{major + 1}.0.0"
            elif f'[NEW_FEATURE:{key}]' in pr_comments:
                return f"{major}.{minor + 1}.0"
            else:
                return f"{major}.{minor}.{patch + 1}"

        # Load package mapping
        package_map = load_package_map()

        # Process only the modified packages
        modified_packages = '${{ steps.order.outputs.modified_packages }}'
        ordered_changes = '${{ steps.order.outputs.ordered_changes }}'  # Used for dependency order only
        pr_comments = '''${{ steps.pr_comment.outputs.result }}'''

        debug_log("Processing modified packages", modified_packages)
        debug_log("Build order", ordered_changes)
        debug_log("PR comments", pr_comments)

        if modified_packages == '[]':
            debug_log("No changes to process")
            sys.exit(0)

        # Remove brackets and split into items and map to full information, properly strip quotes
        items = [package_map[key.strip().strip('"')] for key in modified_packages.strip('[]').split(',')]
        debug_log("Parsed modified items", items)
        
        # First pass: Calculate all new versions for changed libraries
        version_updates = {}
        for item in items:
            try:
                parts = item.split(':')
                library_id = parts[0]  # This is now the library identifier, not the key
                file_path = parts[1]
                
                # Get current version
                current_version = get_version_from_file(file_path)
                
                # Calculate new version using library identifier
                new_version = calculate_new_version(current_version, library_id, pr_comments)
                
                # Store for later use, using library identifier
                version_updates[library_id] = {
                    'file_path': file_path,
                    'new_version': new_version,
                    'current_version': current_version
                }
            except Exception as e:
                debug_log(f"Error processing item: {item}", str(e))
                raise

        debug_log("Version updates to apply", version_updates)

        # Scan all libraries in the workspace
        all_libraries = scan_all_libraries()

        # Second pass: Update versions and dependencies
        version_changes = []
        
        # First update the versions of changed libraries
        for key, info in version_updates.items():
            try:
                # Update the package's own version
                update_version_in_file(info['file_path'], info['new_version'])
                version_changes.append(f"{key}: {info['current_version']} -> {info['new_version']}")
                
                # Update this package's version in ALL libraries that depend on it
                for lib_key, lib_info in all_libraries.items():
                    if key in lib_info['dependencies']:
                        if update_dependency_version(lib_info['file_path'], key, info['new_version']):
                            version_changes.append(f"{lib_key}: Updated dependency {key} to {info['new_version']}")
            except Exception as e:
                debug_log(f"Error updating versions for {key}", str(e))
                raise

        # Print summary
        debug_log("Version changes summary", version_changes)
        print("\nVersion changes summary:")
        for change in version_changes:
            print(change)
        
        # Write output to environment file
        with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
            f.write(f'version_changes={";".join(version_changes)}\n')
        EOF

    - name: Commit Version Updates
      if: steps.versions.outputs.version_changes != ''
      shell: bash
      run: |
        # Configure Git
        git config --local user.email "${{ env.GIT_USER_EMAIL }}"
        git config --local user.name "${{ env.GIT_USER_NAME }}"
        
        # Create .gitignore if it doesn't exist
        if [ ! -f .gitignore ]; then
            echo "scripts/" > .gitignore
        else
            if ! grep -q "^scripts/$" .gitignore; then
                echo "scripts/" >> .gitignore
            fi
        fi
        
        # Make sure the working directory is clean, but preserve scripts
        git clean -fd -e scripts/
        
        # Add and commit changes
        git add -A
        git status
        
        # Try to commit, with error handling
        if ! git commit -m "Update versions based on PR analysis [skip ci]"; then
          echo "No changes to commit or commit failed"
          exit 0
        fi
        
        # Try to push, with retries
        max_attempts=3
        attempt=1
        while [ $attempt -le $max_attempts ]; do
          echo "Push attempt $attempt of $max_attempts"
          if git push; then
            echo "Push successful"
            break
          else
            echo "Push failed, cleaning and retrying..."
            git clean -fd -e scripts/
            git reset --hard HEAD
            git pull --rebase
            ((attempt++))
            if [ $attempt -gt $max_attempts ]; then
              echo "Failed to push after $max_attempts attempts"
              exit 1
            fi
            sleep 5
          fi
        done

    - name: Setup .NET
      uses: actions/setup-dotnet@v4
      with:
        dotnet-version: ${{ env.DOTNET_VERSION }}
        source-url: ${{ env.GITHUB_PACKAGES_URL }}

    - name: Configure NuGet Source
      shell: pwsh
      run: |
        Write-Host "=== Before removing sources ==="
        dotnet nuget list source
        
        # List and remove all existing GitHub sources
        $sources = dotnet nuget list source
        $sources | Where-Object { $_ -match "Github.*" } | ForEach-Object {
            $sourceName = $_.Trim()
            Write-Host "Removing source: $sourceName"
            dotnet nuget remove source $sourceName
        }
        
        Write-Host "=== After removing sources ==="
        dotnet nuget list source
        
        # Add the new source
        Write-Host "Adding new source..."
        dotnet nuget add source "${{ env.GITHUB_PACKAGES_URL }}" `
          --username "${{ github.repository_owner }}" `
          --password "${{ secrets.GITHUB_TOKEN }}" `
          --store-password-in-clear-text
        
        Write-Host "=== Final source configuration ==="
        dotnet nuget list source

    - name: Setup NuGet
      if: steps.order.outputs.has_nuspec == 'true'
      uses: NuGet/setup-nuget@v2
      with:
        nuget-version: '6.x'

    - name: Create Transform Script
      shell: bash
      run: |
        # Create the scripts directory
        mkdir -p scripts
        
        # Create transform script with working directory handling
        cat > scripts/transform.py << 'EOF'
        import json
        import sys
        import os

        def transform_keys(ordered_keys, package_map_path):
            # Ensure we have absolute path
            abs_map_path = os.path.abspath(package_map_path)
            with open(abs_map_path, 'r') as f:
                package_map = json.load(f)
            
            keys = ordered_keys.strip('[]').split(',')
            full_info = [package_map[key.strip()] for key in keys if key.strip()]
            return f"[{','.join(full_info)}]"

        if __name__ == '__main__':
            if len(sys.argv) != 3:
                print('Usage: transform.py <ordered_keys> <package_map_path>')
                sys.exit(1)
            
            ordered_keys = sys.argv[1]
            package_map_path = sys.argv[2]
            print(transform_keys(ordered_keys, package_map_path))
        EOF

    - name: Restore NuGet Dependencies
      if: steps.order.outputs.has_nuspec == 'true'
      shell: bash
      run: |
        ordered_keys="${{ steps.order.outputs.ordered_changes }}"
        changes=$(python3 scripts/transform.py "$ordered_keys" "scripts/package_map.json")
        
        declare -A processed_solutions
        
        echo "$changes" | sed 's/^\[\|\]$//g' | sed 's/"//g' | tr ',' '\n' | while read -r item; do
          item=$(echo "$item" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
          if [ ! -z "$item" ]; then
            path=$(echo "$item" | cut -d':' -f2)
            if [[ $path == *.nuspec ]]; then
              dir=$(dirname "$path")
              echo "Processing directory $dir for NuGet restore"
              
              # Look for solution files in the current directory
              for sln in "$dir"/*.sln; do
                if [ -f "$sln" ] && [ -z "${processed_solutions[$sln]}" ]; then
                  echo "Found solution file $sln in package directory, running nuget restore"
                  nuget restore "$sln"
                  processed_solutions[$sln]=1
                fi
              done
              
              # Look for solution files in the parent directory
              parent_dir=$(dirname "$dir")
              echo "Looking for solutions in parent directory $parent_dir"
              for sln in "$parent_dir"/*.sln; do
                if [ -f "$sln" ] && [ -z "${processed_solutions[$sln]}" ]; then
                  echo "Found solution file $sln in parent directory, running nuget restore"
                  nuget restore "$sln"
                  processed_solutions[$sln]=1
                fi
              done
            fi
          fi
        done

    - name: Build and Pack NuGet Packages
      shell: bash
      run: |
        ordered_keys="${{ steps.order.outputs.ordered_changes }}"
        modified_packages="${{ steps.order.outputs.modified_packages }}"
        changes=$(python3 scripts/transform.py "$ordered_keys" "scripts/package_map.json")
        modified_changes=$(python3 scripts/transform.py "$modified_packages" "scripts/package_map.json")
        
        if [ "$changes" = "[]" ]; then
          echo "No libraries to build and pack"
          exit 0
        fi

        # Create nupkg directory
        mkdir -p ${{ env.OUTPUT_DIR }}

        # Create a temporary file to store modified items
        modified_file=$(mktemp)
        echo "$modified_changes" | sed 's/^\[\|\]$//g' | sed 's/"//g' | tr ',' '\n' | while read -r item; do
          item=$(echo "$item" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
          if [ ! -z "$item" ]; then
            echo "$item" >> "$modified_file"
          fi
        done

        # Process in dependency order, but only build/pack modified packages
        echo "$changes" | sed 's/^\[\|\]$//g' | sed 's/"//g' | tr ',' '\n' | while read -r item; do
          item=$(echo "$item" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
          if [ ! -z "$item" ]; then
            # Check if this item is in the modified set by looking it up in the temp file
            if grep -Fxq "$item" "$modified_file"; then
              path=$(echo "$item" | cut -d':' -f2)
              echo "Processing modified package: $path"

              if [[ $path == *.csproj ]]; then
                echo "Restoring dependencies for $path"
                dotnet restore "$path" --force-evaluate -p:UseNuGetReferences=true
                
                echo "Building and packing $path"
                dotnet build "$path" -c ${{ env.CONFIGURATION }} -p:UseNuGetReferences=true --no-restore
                dotnet pack "$path" -c ${{ env.CONFIGURATION }} --no-build -o ${{ env.OUTPUT_DIR }}
                
                pkg=$(ls -t ${{ env.OUTPUT_DIR }}/*.nupkg | head -n1)
                if [ -f "$pkg" ]; then
                  echo "Publishing $pkg to ${{ env.GITHUB_PACKAGES_URL }}"
                  dotnet nuget push "$pkg" \
                    --api-key "${{ secrets.GITHUB_TOKEN }}" \
                    --source "${{ env.GITHUB_PACKAGES_URL }}" \
                    --skip-duplicate \
                    --no-symbols
                fi
              elif [[ $path == *.nuspec ]]; then
                echo "Building and packing $path"
                dir=$(dirname "$path")
                name=$(basename "$path" .nuspec)
                
                if [ -f "$dir/$name.csproj" ]; then
                  echo "Restoring dependencies for $dir/$name.csproj"
                  dotnet restore "$dir/$name.csproj" --force-evaluate -p:UseNuGetReferences=true
                  
                  echo "Building matching $dir/$name.csproj"
                  dotnet build "$dir/$name.csproj" -c ${{ env.CONFIGURATION }} -p:UseNuGetReferences=true --no-restore
                else
                  for csproj in "$dir"/*.csproj; do
                    if [ -f "$csproj" ]; then
                      echo "Restoring dependencies for $csproj"
                      dotnet restore "$csproj" --force-evaluate -p:UseNuGetReferences=true
                      
                      echo "Building $csproj"
                      dotnet build "$csproj" -c ${{ env.CONFIGURATION }} -p:UseNuGetReferences=true --no-restore
                    fi
                  done
                fi
                
                echo "Packing $path"
                nuget pack "$path" -OutputDirectory ${{ env.OUTPUT_DIR }}
                
                pkg=$(ls -t ${{ env.OUTPUT_DIR }}/*.nupkg | head -n1)
                if [ -f "$pkg" ]; then
                  echo "Publishing $pkg to ${{ env.GITHUB_PACKAGES_URL }}"
                  dotnet nuget push "$pkg" \
                    --api-key "${{ secrets.GITHUB_TOKEN }}" \
                    --source "${{ env.GITHUB_PACKAGES_URL }}" \
                    --skip-duplicate \
                    --no-symbols
                fi
              fi
            else
              echo "Skipping unmodified package in dependency chain: $item"
            fi
          fi
        done

        # Clean up
        rm -f "$modified_file"

    - name: Create Git Tags
      if: steps.versions.outputs.version_changes != ''
      shell: bash
      id: tags
      run: |
        # Configure Git
        git config --local user.email "${{ env.GIT_USER_EMAIL }}"
        git config --local user.name "${{ env.GIT_USER_NAME }}"
        
        # Clean state before creating tags, but preserve scripts
        git clean -fd -e scripts/
        git reset --hard HEAD

        # Create a temporary file to store processed tags
        processed_tags=$(mktemp)

        # First create the release tag
        release_tag="${{ env.PR_BRANCH }}"
        echo "Creating release tag $release_tag"
        # Check if release tag already exists
        if git rev-parse "$release_tag" >/dev/null 2>&1; then
          echo "Release tag $release_tag already exists, skipping..."
        else
          # Try to create and push release tag with retries
          max_attempts=3
          attempt=1
          while [ $attempt -le $max_attempts ]; do
            echo "Release tag push attempt $attempt of $max_attempts"
            if git tag -a "$release_tag" -m "Release $release_tag" && git push origin "$release_tag"; then
              echo "Release tag push successful"
              echo "$release_tag" >> "$processed_tags"
              break
            else
              echo "Release tag push failed, cleaning and retrying..."
              git tag -d "$release_tag" 2>/dev/null || true
              git fetch --tags
              ((attempt++))
              if [ $attempt -gt $max_attempts ]; then
                echo "Failed to push release tag after $max_attempts attempts"
                rm -f "$processed_tags"
                exit 1
              fi
              sleep 5
            fi
          done
        fi

        # Process each version change
        echo '${{ steps.versions.outputs.version_changes }}' | tr ';' '\n' | sort -u | while read -r change; do
          # Skip empty lines
          [ -z "$change" ] && continue
          
          # Extract key and version
          # Assuming format is "KEY: old_version -> new_version" or "KEY: Updated dependency X to new_version"
          key=$(echo "$change" | cut -d':' -f1 | tr -d ' ')
          new_version=$(echo "$change" | grep -o '[0-9]\+\.[0-9]\+\.[0-9]\+$')
          
          if [ ! -z "$key" ] && [ ! -z "$new_version" ]; then
            tag_name="$key/v${new_version}"
            
            # Check if we've already processed this tag
            if ! grep -q "^${tag_name}$" "$processed_tags"; then
              echo "$tag_name" >> "$processed_tags"
              
              echo "Creating tag $tag_name"
              # Check if tag already exists
              if git rev-parse "$tag_name" >/dev/null 2>&1; then
                echo "Tag $tag_name already exists, skipping..."
                continue
              fi
              
              # Try to create and push tag with retries
              max_attempts=3
              attempt=1
              while [ $attempt -le $max_attempts ]; do
                echo "Tag push attempt $attempt of $max_attempts"
                if git tag -a "$tag_name" -m "Release $key version ${new_version}" && git push origin "$tag_name"; then
                  echo "Tag push successful"
                  break
                else
                  echo "Tag push failed, cleaning and retrying..."
                  git tag -d "$tag_name" 2>/dev/null || true
                  git fetch --tags
                  ((attempt++))
                  if [ $attempt -gt $max_attempts ]; then
                    echo "Failed to push tag after $max_attempts attempts"
                    rm -f "$processed_tags"
                    exit 1
                  fi
                  sleep 5
                fi
              done
            else
              echo "Tag $tag_name was already processed in this run, skipping..."
            fi
          else
            echo "Could not parse version change: $change"
            echo "Key: $key"
            echo "New version: $new_version"
          fi
        done

        # Store the processed tags as a step output
        echo "tags<<EOF" >> $GITHUB_OUTPUT
        cat "$processed_tags" >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT

        # Clean up temporary file
        rm -f "$processed_tags"

    - name: Print Changed Libraries
      id: print_changes
      shell: bash
      run: |
        output_file=$(mktemp)
        ordered_keys="${{ steps.order.outputs.ordered_changes }}"
        modified_packages="${{ steps.order.outputs.modified_packages }}"
        changes=$(python3 scripts/transform.py "$ordered_keys" "scripts/package_map.json")
        modified_changes=$(python3 scripts/transform.py "$modified_packages" "scripts/package_map.json")
        
        if [ "$modified_changes" = "[]" ]; then
          echo "No libraries were changed" | tee "$output_file"
        else
          {
            echo "# Changes Summary"
            echo ""
            echo "## Changed Libraries"
            filtered_changes=$(echo "$modified_changes" | sed 's/^\[\|\]$//g' | sed 's/"//g')
            
            echo "$filtered_changes" | tr ',' '\n' | while read -r item; do
              item=$(echo "$item" | sed 's/^[[:space:]]*//;s/[[:space:]]*$//')
              if [ ! -z "$item" ]; then
                key=$(echo "$item" | cut -d':' -f1)
                path=$(echo "$item" | cut -d':' -f2)
                deps=$(echo "$item" | cut -d':' -f3)
                ext=$(echo "$path" | grep -o '\.[^.]*$' | sed 's/\.//' || echo "no extension")
                if [ ! -z "$key" ]; then
                  echo "* Package $key"
                  echo "  * Path: \\\`$path\\\`"
                  echo "  * Dependencies: ${deps:-none}"
                  echo "  * File type: $ext"
                  echo ""
                fi
              fi
            done
            
            echo "## Version Changes"
            if [ ! -z "${{ steps.versions.outputs.version_changes }}" ]; then
              echo "${{ steps.versions.outputs.version_changes }}" | tr ';' '\n' | while read -r change; do
                if [ ! -z "$change" ]; then
                  echo "* $change"
                fi
              done
            else
              echo "No version changes detected"
            fi

            echo ""
            echo "## Created Tags"
            echo "${{ steps.tags.outputs.tags }}" | while read -r tag; do
              if [ ! -z "$tag" ]; then
                echo "* \\\`$tag\\\`"
              fi
            done

            echo ""
            echo "## Package Information"
            echo "* Package Registry: https://github.com/${{ github.repository }}/packages"
            echo "* NuGet Source: https://nuget.pkg.github.com/${{ github.repository_owner }}/index.json"
            echo "* Required Authentication: GitHub Personal Access Token with \\\`read:packages\\\` scope"
            echo "* Note: See repository documentation for detailed setup instructions"
          } | tee "$output_file"
        fi

        echo "summary<<EOF" >> $GITHUB_OUTPUT
        cat "$output_file" >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT
        rm -f "$output_file"

    - name: Add Changes Summary Comment
      if: steps.order.outputs.ordered_changes != '[]'
      uses: actions/github-script@v7
      with:
        script: |
          const summary = `${{ steps.print_changes.outputs.summary }}`
            .replace(/\\\`/g, '`'); // Convert escaped backticks back to regular backticks
          await github.rest.issues.createComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
            body: summary
          });  